{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\thoma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\thoma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\thoma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\thoma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\thoma\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "# from konlpy.tag import Mecab\n",
    "from nltk.tokenize import word_tokenize as en_tokenizer\n",
    "import sentencepiece as spm\n",
    "import urllib.request\n",
    "import csv\n",
    "import numpy as np\n",
    "from einops import rearrange, reduce, repeat\n",
    "from torch.cuda import amp\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import time\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import gc\n",
    "import os\n",
    "from icecream import ic\n",
    "# 어느 코드에서 진행된 것인지\n",
    "# debug할 때 편리함을 줌!\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 5000\n",
    "SEQ_LEN = 60\n",
    "\n",
    "\n",
    "PAD_IDX = 0\n",
    "BOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "\n",
    "\n",
    "# ENV = 'COLAB'\n",
    "ENV = 'KAGGLE'\n",
    "# ENV = 'SYSTEM'\n",
    "\n",
    "# Option for Mixed Precision\n",
    "FP16 = True\n",
    "# FP16 = False\n",
    "\n",
    "N = 2\n",
    "HIDDEN_DIM = 256\n",
    "NUM_HEAD = 8 \n",
    "INNER_DIM = 512\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 0\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    'VOCAB_SIZE': VOCAB_SIZE,\n",
    "    'SEQ_LEN': SEQ_LEN,\n",
    "    'N': N,\n",
    "    'HIDDEN_DIM': HIDDEN_DIM,\n",
    "    'NUM_HEAD': NUM_HEAD,\n",
    "    'INNER_DIM': INNER_DIM,\n",
    "    'BATCH_SIZE': BATCH_SIZE,\n",
    "    'WEIGHT_DECAY' : WEIGHT_DECAY,\n",
    "    'LEARNING_RATE' : LEARNING_RATE,\n",
    "}\n",
    "\n",
    "\n",
    "if 'device' not in globals():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data load에선 문제가 생겨 추후 문제점 해결하려고 함 (wandb에 github id를 활용하여 id 생성 후 연결하는 작업 진행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport wandb\\nimport os\\n# if want to run in offline mode\\n\\n# os.environ[\"WANDB_MODE\"] = \"dryrun\"\\n# wandb.init(project=\"Transformer_bible\", entity=\"jiwon7258\")\\nos.environ[\"WANDB_MODE\"] = \"online\"\\n\\nwandb.init(project=\"Transformer_bible\", entity=\"thomas7225\", config = CONFIG, job_type = \\'train\\')\\nwandb.run.name = f\"train_{VOCAB_SIZE}_{SEQ_LEN}_{N}_{HIDDEN_DIM}_{INNER_DIM}\"\\n\\n\\ndataset = wandb.Artifact(f\\'bible-dataset_{VOCAB_SIZE}_{SEQ_LEN}\\', type=\\'dataset\\')4\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import wandb\n",
    "import os\n",
    "# if want to run in offline mode\n",
    "\n",
    "# os.environ[\"WANDB_MODE\"] = \"dryrun\"\n",
    "# wandb.init(project=\"Transformer_bible\", entity=\"jiwon7258\")\n",
    "os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "\n",
    "wandb.init(project=\"Transformer_bible\", entity=\"thomas7225\", config = CONFIG, job_type = 'train')\n",
    "wandb.run.name = f\"train_{VOCAB_SIZE}_{SEQ_LEN}_{N}_{HIDDEN_DIM}_{INNER_DIM}\"\n",
    "\n",
    "\n",
    "dataset = wandb.Artifact(f'bible-dataset_{VOCAB_SIZE}_{SEQ_LEN}', type='dataset')4\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndataset = wandb.run.use_artifact(f'bible-dataset_{VOCAB_SIZE}_{SEQ_LEN}:latest')\\n\\n# Download the artifact's contents\\nartifact_dir = dataset.download()\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dataset = wandb.run.use_artifact(f'bible-dataset_{VOCAB_SIZE}_{SEQ_LEN}:latest')\n",
    "\n",
    "# Download the artifact's contents\n",
    "artifact_dir = dataset.download()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# or Train / Valid Data\\nsrc_train_path = os.path.join(artifact_dir,'src_train.pkl')\\nsrc_valid_path = os.path.join(artifact_dir,'src_valid.pkl')\\ntrg_train_path = os.path.join(artifact_dir,'trg_train.pkl')\\ntrg_valid_path = os.path.join(artifact_dir,'trg_valid.pkl')\\n\\nsrc_train = joblib.load(src_train_path)\\nsrc_valid = joblib.load(src_valid_path)\\ntrg_train = joblib.load(trg_train_path)\\ntrg_valid = joblib.load(trg_valid_path)\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# or Train / Valid Data\n",
    "src_train_path = os.path.join(artifact_dir,'src_train.pkl')\n",
    "src_valid_path = os.path.join(artifact_dir,'src_valid.pkl')\n",
    "trg_train_path = os.path.join(artifact_dir,'trg_train.pkl')\n",
    "trg_valid_path = os.path.join(artifact_dir,'trg_valid.pkl')\n",
    "\n",
    "src_train = joblib.load(src_train_path)\n",
    "src_valid = joblib.load(src_valid_path)\n",
    "trg_train = joblib.load(trg_train_path)\n",
    "trg_valid = joblib.load(trg_valid_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새로운 방법론 (데이터셋 직접다운)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genesis1.1  In the beginning God created the heavens and the earth.', 'Genesis1.2  Now the earth was formless and empty, darkness was over the surface of the deep, and the Spirit of God was hovering over the waters.', 'Genesis1.3  And God said, \"Let there be light,\" and there was light.', 'Genesis1.4  God saw that the light was good, and He separated the light from the darkness.', 'Genesis1.5  God called the light \"day,\" and the darkness he called \"night.\" And there was evening, and there was morning--the first day.', 'Genesis1.6  And God said, \"Let there be an expanse between the waters to separate water from water.\"', 'Genesis1.7  So God made the expanse and separated the water under the expanse from the water above it. And it was so.', 'Genesis1.8  God called the expanse \"sky.\" And there was evening, and there was morning--the second day.', 'Genesis1.9  And God said, \"Let the water under the sky be gathered to one place, and let dry ground appear.\" And it was so.', 'Genesis1.10  God called the dry ground \"land,\" and the gathered waters he called \"seas.\" And God saw that it was good.']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATASET_PATH = './data'\n",
    "\n",
    "# 파일을 열 때 인코딩 방식을 UTF-8로 지정\n",
    "with open(os.path.join(DATASET_PATH, 'bible-all.en.txt'), encoding='utf-8') as en_train:\n",
    "    en_train_content = en_train.read()\n",
    "en_train_list = en_train_content.split('\\n')\n",
    "\n",
    "with open(os.path.join(DATASET_PATH, 'bible-all.kr.txt'), encoding='utf-8') as ko_train:\n",
    "    ko_train_content = ko_train.read()\n",
    "ko_train_list = ko_train_content.split('\\n')\n",
    "\n",
    "# 첫 10개 항목을 출력\n",
    "print(en_train_list[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31104\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_raw</th>\n",
       "      <th>ko_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis1.1  In the beginning God created the h...</td>\n",
       "      <td>Genesis1.1  태초에 하나님이 천지를 창조하셨다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genesis1.2  Now the earth was formless and emp...</td>\n",
       "      <td>Genesis1.2  땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Genesis1.3  And God said, \"Let there be light,...</td>\n",
       "      <td>Genesis1.3  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genesis1.4  God saw that the light was good, a...</td>\n",
       "      <td>Genesis1.4  그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genesis1.5  God called the light \"day,\" and th...</td>\n",
       "      <td>Genesis1.5  빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              en_raw  \\\n",
       "0  Genesis1.1  In the beginning God created the h...   \n",
       "1  Genesis1.2  Now the earth was formless and emp...   \n",
       "2  Genesis1.3  And God said, \"Let there be light,...   \n",
       "3  Genesis1.4  God saw that the light was good, a...   \n",
       "4  Genesis1.5  God called the light \"day,\" and th...   \n",
       "\n",
       "                                              ko_raw  \n",
       "0                    Genesis1.1  태초에 하나님이 천지를 창조하셨다.  \n",
       "1  Genesis1.2  땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영...  \n",
       "2      Genesis1.3  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.  \n",
       "3   Genesis1.4  그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,  \n",
       "4  Genesis1.5  빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 ...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data['en_raw'] = en_train_list\n",
    "data['ko_raw'] = ko_train_list\n",
    "data = data.reset_index(drop = True)\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['en'] = data['en_raw'].apply(lambda x: x.split(' ')[1:])\n",
    "data['en'] = data['en'].apply(lambda x: (' ').join(x))\n",
    "data['ko'] = data['ko_raw'].apply(lambda x: x.split(' ')[1:])\n",
    "data['ko'] = data['ko'].apply(lambda x: (' ').join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ko</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the beginning God created the heavens and ...</td>\n",
       "      <td>태초에 하나님이 천지를 창조하셨다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now the earth was formless and empty, darknes...</td>\n",
       "      <td>땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영은 물 위에 움직이고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And God said, \"Let there be light,\" and there...</td>\n",
       "      <td>하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>God saw that the light was good, and He separ...</td>\n",
       "      <td>그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>God called the light \"day,\" and the darkness ...</td>\n",
       "      <td>빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 아침이 되니, 하루가...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0   In the beginning God created the heavens and ...   \n",
       "1   Now the earth was formless and empty, darknes...   \n",
       "2   And God said, \"Let there be light,\" and there...   \n",
       "3   God saw that the light was good, and He separ...   \n",
       "4   God called the light \"day,\" and the darkness ...   \n",
       "\n",
       "                                                  ko  \n",
       "0                                태초에 하나님이 천지를 창조하셨다.  \n",
       "1   땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영은 물 위에 움직이고...  \n",
       "2                  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.  \n",
       "3               그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,  \n",
       "4   빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 아침이 되니, 하루가...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['en','ko']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 사전 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('src.txt', mode = 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(data['en']))\n",
    "with open('trg.txt', mode= 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(data['ko']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture context\n",
    "corpus = \"src.txt\"\n",
    "prefix = \"src\"\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={VOCAB_SIZE}\" +\n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" +  # 문장 최대 길이\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" +  # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" +  # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" +  # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" +  # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\");  # 사용자 정의 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture context\n",
    "corpus = \"trg.txt\"\n",
    "prefix = \"trg\"\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={VOCAB_SIZE}\" +\n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" +  # 문장 최대 길이\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" +  # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" +  # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" +  # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" +  # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\");  # 사용자 정의 토큰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁In', '▁the', '▁beginning', '▁God', '▁created', '▁the', '▁heavens', '▁and', '▁the', '▁earth', '.']\n",
      "[502, 10, 2155, 133, 3212, 10, 1354, 19, 10, 458, 4961]\n",
      "['▁Now', '▁the', '▁earth', '▁was', '▁form', 'less', '▁and', '▁empty', ',', '▁darkness', '▁was', '▁over', '▁the', '▁sur', 'f', 'ace', '▁of', '▁the', '▁deep', ',', '▁and', '▁the', '▁Spirit', '▁of', '▁God', '▁was', '▁ho', 'ver', 'ing', '▁over', '▁the', '▁waters', '.']\n",
      "[589, 10, 458, 127, 3464, 636, 19, 3330, 4958, 1451, 127, 268, 10, 1018, 4953, 231, 21, 10, 1685, 4958, 19, 10, 837, 21, 133, 127, 386, 94, 39, 268, 10, 1411, 4961]\n",
      "['▁And', '▁God', '▁said', ',', '▁\"', 'Let', '▁there', '▁be', '▁light', ',\"', '▁and', '▁there', '▁was', '▁light', '.']\n",
      "[288, 133, 150, 4958, 65, 1612, 250, 52, 897, 393, 19, 250, 127, 897, 4961]\n"
     ]
    }
   ],
   "source": [
    "sp_src = spm.SentencePieceProcessor()\n",
    "sp_src.Load('src.model')\n",
    "\n",
    "\n",
    "for idx in range(3):\n",
    "    sentence = data['en'][idx]\n",
    "    print(sp_src.EncodeAsPieces(sentence))\n",
    "    print(sp_src.EncodeAsIds(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_encode(tmpstr:str) -> np.array :\n",
    "    tmpstr = np.array(sp_src.EncodeAsIds(tmpstr))\n",
    "\n",
    "    # SEQ_LEN보다 길면 짜른다 \n",
    "    if len(tmpstr) > SEQ_LEN :\n",
    "        tmpstr = tmpstr[:SEQ_LEN]\n",
    "\n",
    "    # SEQ_LEN보다 작으면 padding\n",
    "    else :\n",
    "        tmpstr = np.pad(tmpstr, (0, SEQ_LEN - len(tmpstr)), 'constant', constant_values = sp_src.pad_id())\n",
    "    \n",
    "    return tmpstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 502,   10, 2155,  133, 3212,   10, 1354,   19,   10,  458, 4961,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# src_data는 data['en']를 참조한다. (동일 id)\n",
    "src_data = data['en']\n",
    "\n",
    "src_list = []\n",
    "\n",
    "for idx in range(len(src_data)):\n",
    "    src_list.append(en_encode(src_data[idx]))\n",
    "\n",
    "src_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁태', '초', '에', '▁하나님이', '▁천', '지를', '▁창조', '하셨다', '.']\n",
      "[561, 4349, 3964, 213, 369, 513, 2208, 883, 3962]\n",
      "['▁땅이', '▁혼', '돈', '하고', '▁공', '허', '하며', ',', '▁어둠', '이', '▁깊', '음', '▁위에', '▁있고', ',', '▁하나님의', '▁영', '은', '▁물', '▁위에', '▁움', '직', '이고', '▁계', '셨다', '.']\n",
      "[1226, 1567, 4398, 106, 440, 4291, 455, 3961, 1710, 3959, 1114, 4043, 394, 696, 3961, 194, 153, 3978, 119, 394, 2892, 4226, 411, 193, 91, 3962]\n",
      "['▁하나님이', '▁말씀하시기를', '▁\"', '빛', '이', '▁생', '겨', '라', '\"', '▁하시니', ',', '▁빛이', '▁생', '겼다', '.']\n",
      "[213, 2045, 32, 4386, 3959, 171, 4156, 3983, 3995, 2921, 3961, 3057, 171, 1450, 3962]\n"
     ]
    }
   ],
   "source": [
    "sp_trg = spm.SentencePieceProcessor()\n",
    "sp_trg.Load('trg.model')\n",
    "\n",
    "\n",
    "for idx in range(3):\n",
    "    sentence = data['ko'][idx]\n",
    "    print(sp_trg.EncodeAsPieces(sentence))\n",
    "    print(sp_trg.EncodeAsIds(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ko_encode(tmpstr: str) -> np.array:\n",
    "    tmpstr = np.array(sp_trg.EncodeAsIds(tmpstr))\n",
    "    tmpstr = np.insert(tmpstr, 0, sp_trg.bos_id())\n",
    "\n",
    "    if len(tmpstr) >= SEQ_LEN:\n",
    "        # SEQ_LEN -1의 길이로 자른다\n",
    "        tmpstr = tmpstr[:SEQ_LEN-1]\n",
    "        # 마지막에 <eos> 토큰을 넣어줌으로써, 길이를 SEQ_LEN으로 맞춘다\n",
    "        tmpstr = np.pad(tmpstr, (0, 1),\n",
    "                        'constant', constant_values=sp_trg.eos_id())\n",
    "\n",
    "\n",
    "    else:\n",
    "        tmpstr = np.pad(tmpstr, (0, 1),\n",
    "                        'constant', constant_values=sp_trg.eos_id())\n",
    "        tmpstr = np.pad(tmpstr, (0, SEQ_LEN - len(tmpstr)),\n",
    "                        'constant', constant_values=sp_trg.pad_id())\n",
    "\n",
    "    return tmpstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,  561, 4349, 3964,  213,  369,  513, 2208,  883, 3962,    3,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trg_data는 data['ko']를 참조한다. (동일 id)\n",
    "trg_data = data['ko']\n",
    "\n",
    "trg_list = []\n",
    "\n",
    "for idx in range(len(trg_data)):\n",
    "    trg_list.append(ko_encode(trg_data[idx]))   \n",
    "\n",
    "trg_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_train, src_valid, trg_train, trg_valid = train_test_split(src_list, trg_list, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, src_data, trg_data):\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(src_data) == len(trg_data)\n",
    "\n",
    "        self.src_data = src_data\n",
    "        self.trg_data = trg_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_data)\n",
    "        \n",
    "    def __getitem__ (self, idx):\n",
    "        src = self.src_data[idx]\n",
    "        trg_input = self.trg_data[idx]\n",
    "        trg_output = trg_input[1:SEQ_LEN]\n",
    "        trg_output = np.pad(trg_output, (0,1), 'constant', constant_values =0)\n",
    "        # (seq_len,)\n",
    "        return torch.Tensor(src).long(), torch.Tensor(trg_input).long(), torch.Tensor(trg_output).long()\n",
    "\n",
    "train_dataset = TrainDataset(src_train, trg_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle= True, pin_memory=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidDataset(Dataset):\n",
    "    def __init__(self, src_data, trg_data):\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(src_data) == len(trg_data)\n",
    "\n",
    "        self.src_data = src_data\n",
    "        self.trg_data = trg_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_data)\n",
    "        \n",
    "    def __getitem__ (self, idx):\n",
    "        src = self.src_data[idx]\n",
    "        trg_input = self.trg_data[idx]\n",
    "        trg_output = trg_input[1:SEQ_LEN]\n",
    "        trg_output = np.pad(trg_output, (0,1), 'constant',constant_values= 0)\n",
    "\n",
    "        return torch.Tensor(src).long(), torch.Tensor(trg_input).long(), torch.Tensor(trg_output).long()\n",
    "\n",
    "valid_dataset = ValidDataset(src_valid, trg_valid)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle= False, pin_memory=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask 행렬을 반환하는 Mask Function\n",
    "# Masking은 QK_T 중 srcK 의 seq_len을 중심으로 한다는 점을 알아두자!!\n",
    "'''\n",
    "Input\n",
    "- Tensor\n",
    "    shape (bs, srcK seq_len)\n",
    "Args\n",
    "- Option\n",
    "    If option is 'padding', function returns padding mask\n",
    "    If option is 'lookahead', function returns lookahead mask\n",
    "Output\n",
    "- Tensor (option = 'padding' )\n",
    "    shape (bs, 1, 1, srcK seq_len)\n",
    "    \n",
    "* shape 중 (1, 1) 부분은 broad casting을 위한 것이다.\n",
    "'''\n",
    "def makeMask(tensor, option: str) -> torch.Tensor:\n",
    "    '''\n",
    "    tensor (bs, seq_len)\n",
    "    '''\n",
    "    if option == 'padding':\n",
    "        tmp = torch.full_like(tensor, fill_value=PAD_IDX).to(device)\n",
    "        # tmp : (bs,seq_len)\n",
    "        mask = (tensor != tmp).float()\n",
    "        # mask : (bs, seq_len)\n",
    "        mask = rearrange(mask, 'bs seq_len -> bs 1 1 seq_len ')\n",
    "        \n",
    "        # mask(bs, 1, seq_len,seq_len)\n",
    "\n",
    "        '''\n",
    "        Example of mask\n",
    "        tensor([[\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n",
    "        '''\n",
    "\n",
    "    elif option == 'lookahead':\n",
    "        # srcQ의 seq_len과 srcK의 seq_len이 동일하다고 가정한다\n",
    "        # tensor : (bs, seq_len)\n",
    "\n",
    "        padding_mask = makeMask(tensor, 'padding')\n",
    "        padding_mask = repeat(\n",
    "            padding_mask, 'bs 1 1 k_len -> bs 1 new k_len', new=padding_mask.shape[3])\n",
    "        # padding_mask : (bs, 1, seq_len, seq_len)\n",
    "\n",
    "        '''\n",
    "        Example of padding_mask\n",
    "        tensor([[\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n",
    "        '''\n",
    "        mask = torch.ones_like(padding_mask)\n",
    "        mask = torch.tril(mask)\n",
    "\n",
    "        '''\n",
    "        Example of 'mask'\n",
    "        tensor([[\n",
    "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
    "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
    "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
    "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
    "        '''\n",
    "\n",
    "        mask = mask * padding_mask\n",
    "        # ic(mask.shape)\n",
    "\n",
    "        '''\n",
    "        Example\n",
    "        tensor([[\n",
    "         [1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "         [1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "         [1., 1., 1., 0., 0., 0., 0., 0.],\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n",
    "        '''\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test code를 통해 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " padding  옵션에 대한 출력 \n",
      " => tensor([[[[1., 1., 1., 1., 1., 1., 0., 0., 0., 0.]]]])\n",
      "\n",
      "lookahead 옵션에 대한 출력 \n",
      " => tensor([[[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "test = torch.Tensor([[1,2,3,4,5,6,0,0,0,0]])\n",
    "ic(test.shape)\n",
    "# option padding => 0이 아닌 값에 대해서 1의 값을 줌\n",
    "test1 = makeMask(test, option = 'padding')\n",
    "# option lookahead \n",
    "# repeat => 차원을 확장시킴 ex) 10X1 => 10X10\n",
    "# ones_like => 해당 행렬을 하삼각행렬의 형태로 만들어줌\n",
    "# mask를 통해 masking 진행\n",
    "# masking을 통해 미래 정보를 반영하지 않게 함\n",
    "test2 = makeMask(test, option = 'lookahead')\n",
    "ic(test1.shape)\n",
    "print()\n",
    "print(\" padding  옵션에 대한 출력 \\n =>\", test1)\n",
    "print()\n",
    "ic(test2.shape)\n",
    "print(\"lookahead 옵션에 대한 출력 \\n =>\", test2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multihead Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multiheadattention(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, num_head: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # embedding_dim, d_model, 512 in paper\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # 8 in paper\n",
    "        self.num_head = num_head\n",
    "        # head_dim, d_key, d_query, d_value, 64 in paper (= 512 / 8)\n",
    "        self.head_dim = hidden_dim // num_head\n",
    "        self.scale = torch.sqrt(torch.FloatTensor()).to(device)\n",
    "\n",
    "        \n",
    "        # query, key, value 값에 대해 선형변환을 진행해준다.\n",
    "        # 새로운 차원(데이터)으로 매핑시켜준다 (단, 해당코드에서는 차원이 변하지 않음)\n",
    "        \n",
    "        self.fcQ = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fcK = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fcV = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fcOut = nn.Linear(hidden_dim, hidden_dim)\n",
    "        #dropout으로 과적합 방지\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    # 순전파 과정\n",
    "    def forward(self, srcQ, srcK, srcV, mask=None):\n",
    "\n",
    "        ##### SCALED DOT PRODUCT ATTENTION ######\n",
    "        # \n",
    "        # input : (bs(= batchsize), seq_len, hidden_dim)\n",
    "        Q = self.fcQ(srcQ)\n",
    "        K = self.fcK(srcK)\n",
    "        V = self.fcV(srcV)\n",
    "        # 텐서의 차원을 변환하고 재배치하는 역할 \n",
    "        # 주어진 텐서의 차원을 재구성하여 원하는 형태로 바꾸는 데 사용\n",
    "        # ()안에 있다면 값을 곱해주는 것임\n",
    "        # num_head => mutli head의 개수\n",
    "        # seq_len => sequence length (문장의 갯수)\n",
    "        # head_dim => embedding 시킨 input 차원\n",
    "        Q = rearrange(\n",
    "            Q, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n",
    "        K_T = rearrange(\n",
    "            K, 'bs seq_len (num_head head_dim) -> bs num_head head_dim seq_len', num_head=self.num_head)\n",
    "        V = rearrange(\n",
    "            V, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n",
    "\n",
    "        attention_energy = torch.matmul(Q, K_T)\n",
    "        # attention_energy : (bs, num_head, q_len, k_len)\n",
    "\n",
    "        if mask is not None :\n",
    "            '''\n",
    "            mask.shape\n",
    "            if padding : (bs, 1, 1, k_len)\n",
    "            if lookahead : (bs, 1, q_len, k_len)\n",
    "            '''\n",
    "            # masking 해야될 곳에 큰 음수의 값을 지정해준다\n",
    "            attention_energy = torch.masked_fill(attention_energy, (mask == 0), -1e+4)\n",
    "        \n",
    "        # softmax를 활용을 통해 확률분포로 변환하는 과정\n",
    "        attention_energy = torch.softmax(attention_energy, dim = -1)\n",
    "\n",
    "        result = torch.matmul(self.dropout(attention_energy),V)\n",
    "        # result (bs, num_head, seq_len, head_dim)\n",
    "\n",
    "        ##### END OF SCALED DOT PRODUCT ATTENTION ######\n",
    "\n",
    "        # CONCAT\n",
    "        result = rearrange(result, 'bs num_head seq_len head_dim -> bs seq_len (num_head head_dim)')\n",
    "        # result : (bs, seq_len, hidden_dim)\n",
    "\n",
    "        # LINEAR\n",
    "\n",
    "        result = self.fcOut(result)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 10])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST CODE #\n",
    "bs = 1\n",
    "hidden_dim = 10\n",
    "src = torch.Tensor([[1,2,3,4,5,6,0,0,0,0]])\n",
    "ic(src.shape)\n",
    "padding_mask = makeMask(src, option = 'padding')\n",
    "ic(padding_mask.shape)\n",
    "lookahead_mask = makeMask(src, option = 'lookahead')\n",
    "ic(lookahead_mask.shape)\n",
    "\n",
    "\n",
    "test_Q = torch.randn((bs,2,10))\n",
    "test_K = rearrange(src, 'seq_len hidden_dim -> 1 seq_len hidden_dim')\n",
    "ic(test_K.shape)\n",
    "test_K = repeat(src, 'seq_len hidden_dim -> 1 (10 seq_len) hidden_dim')\n",
    "ic(test_Q.shape)\n",
    "ic(test_K.shape)\n",
    "test_layer = Multiheadattention(hidden_dim=hidden_dim, num_head =2)\n",
    "ic(test_layer(srcQ = test_Q, srcK = test_K, srcV = test_K, mask = padding_mask).shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positionwise Feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__ (self, hidden_dim, inner_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # 512 in paper \n",
    "        self.hidden_dim = hidden_dim\n",
    "        # 2048 in paper\n",
    "        self.inner_dim = inner_dim \n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim, inner_dim)\n",
    "        self.fc2 = nn.Linear(inner_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = input\n",
    "        output = self.fc1(output)\n",
    "        output2 = self.relu(output)\n",
    "        output2 = self.dropout(output)\n",
    "        output3 = self.fc2(output2)\n",
    "\n",
    "        return output3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_head, inner_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_head = num_head\n",
    "        self.inner_dim = inner_dim\n",
    "        \n",
    "        self.multiheadattention = Multiheadattention(hidden_dim, num_head)\n",
    "        self.ffn = FFN(hidden_dim, inner_dim)\n",
    "        #layernorm -> layer 정규화를 진행\n",
    "        self.layerNorm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.layerNorm2 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "\n",
    "\n",
    "    def forward(self, input, mask = None):\n",
    "\n",
    "        # input : (bs, seq_len, hidden_dim)\n",
    "        \n",
    "        # 드롭아웃 및 잔차연결\n",
    "        output = self.multiheadattention(srcQ= input, srcK = input, srcV = input, mask = mask)\n",
    "        output = self.dropout1(output)\n",
    "        output = input + output\n",
    "        output = self.layerNorm1(output)\n",
    "\n",
    "        output_ = self.ffn(output)\n",
    "        output_ = self.dropout2(output_)\n",
    "        output = output + output_\n",
    "        output = self.layerNorm2(output)\n",
    "\n",
    "        # output : (bs, seq_len, hidden_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__ (self, N, hidden_dim, num_head, inner_dim,max_length=100):\n",
    "        super().__init__()\n",
    "\n",
    "        # N : encoder layer의 층\n",
    "        self.N = N\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_head = num_head\n",
    "        self.inner_dim = inner_dim\n",
    "\n",
    "        # embedding 해줌\n",
    "        # nn.ModuleList -> module의 List를 관리\n",
    "        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
    "        self.enc_layers = nn.ModuleList([EncoderLayer(hidden_dim, num_head, inner_dim) for _ in range(N)])\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        seq_len = input.shape[1]\n",
    "        # input : (bs, seq_len)\n",
    "\n",
    "        mask = makeMask(input, option='padding')\n",
    "\n",
    "        #arrange() => ()안에 값들을 순서대로 나열해줌 \n",
    "        # pos => 위치 인덱스를 생성(각 시퀀스 길이에 대해)\n",
    "        pos = torch.arange(0, seq_len).unsqueeze(0).repeat(batch_size, 1).to(device)\n",
    "        # pos: [batch_size, src_len]\n",
    "\n",
    "        # embedding layer\n",
    "        output = self.dropout(self.embedding(input) + self.pos_embedding(pos))\n",
    "        # output : (bs, seq_len, hidden_dim)\n",
    "\n",
    "\n",
    "        # Positional Embedding\n",
    "        # output = pos_embed(output)\n",
    "\n",
    "        # Dropout\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        # N개의 layer를 순차적으로 돌게 만들어줌\n",
    "        for layer in self.enc_layers:\n",
    "            output = layer(output, mask)\n",
    "\n",
    "        # output : (bs, seq_len, hidden_dim)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_head, inner_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_head = num_head\n",
    "        self.inner_dim = inner_dim\n",
    "\n",
    "        \n",
    "        # 2개의 multiheadattention\n",
    "        # 1개의 FeedForward Network\n",
    "        self.multiheadattention1 = Multiheadattention(hidden_dim, num_head)\n",
    "        self.layerNorm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.multiheadattention2 = Multiheadattention(hidden_dim, num_head)\n",
    "        self.layerNorm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.ffn = FFN(hidden_dim, inner_dim)\n",
    "        self.layerNorm3 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    \n",
    "    def forward(self, input, enc_output, paddingMask, lookaheadMask):\n",
    "        # input : (bs, seq_len, hidden_dim)\n",
    "        # enc_output : (bs, seq_len, hidden_dim)\n",
    "\n",
    "        # 1번째 multiheadattention\n",
    "        # 드롭아웃 및 잔차연결\n",
    "        output = self.multiheadattention1(input, input, input, lookaheadMask)\n",
    "        output = self.dropout1(output)\n",
    "        output = output + input\n",
    "        output = self.layerNorm1(output)\n",
    "\n",
    "\n",
    "        # 2번째 multiheadattention\n",
    "        # 드롭아웃 및 잔차연결\n",
    "        output_ = self.multiheadattention2(output, enc_output, enc_output, paddingMask)\n",
    "        output_ = self.dropout2(output_)\n",
    "        output = output_ + output\n",
    "        output = self.layerNorm2(output)\n",
    "\n",
    "\n",
    "\n",
    "        # Feedforward Network\n",
    "        # 드롭아웃 및 잔차연결\n",
    "        output_ = self.ffn(output)\n",
    "        output_ = self.dropout3(output_)\n",
    "        output = output + output_\n",
    "        output = self.layerNorm3(output)\n",
    "\n",
    "\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__ (self, N, hidden_dim, num_head, inner_dim, max_length=100):\n",
    "        super().__init__()\n",
    "\n",
    "        # N : number of encoder layer repeated \n",
    "        self.N = N\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_head = num_head\n",
    "        self.inner_dim = inner_dim\n",
    "\n",
    "        # embedding layer 설정\n",
    "        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
    "\n",
    "        # decoder N개 생성\n",
    "        self.dec_layers = nn.ModuleList([DecoderLayer(hidden_dim, num_head, inner_dim) for _ in range(N)])\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        #최종 선형변환에 필요한 Linear작업\n",
    "        self.finalFc = nn.Linear(hidden_dim, VOCAB_SIZE)\n",
    "\n",
    "\n",
    "    def forward(self, input, enc_src, enc_output):\n",
    "\n",
    "        # input = dec_src : (bs, seq_len)\n",
    "        # enc_src : (bs, seq_len)\n",
    "        # enc_output : (bs, seq_len,hidden_dim)\n",
    "        \n",
    "        lookaheadMask = makeMask(input, option= 'lookahead')\n",
    "        paddingMask = makeMask(enc_src, option = 'padding')\n",
    "\n",
    "        # embedding layer\n",
    "        output = self.embedding(input)\n",
    "        # output = (bs, seq_len, hidden_dim)\n",
    "\n",
    "\n",
    "        # Positional Embedding\n",
    "        # output = pos_embed(output)\n",
    "\n",
    "        # Dropout\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        # N decoder layer\n",
    "        for layer in self.dec_layers:\n",
    "            output = layer(output, enc_output, paddingMask, lookaheadMask)\n",
    "        # output : (bs, seq_len, hidden_dim)\n",
    "\n",
    "        # 최종값이기 때문에 for문 밖에서 진행해주어야됨\n",
    "        # 해당 vocab에 맞게 차원을 변환\n",
    "        logits = self.finalFc(output)\n",
    "        # logits : (bs, seq_len, VOCAB_SIZE)\n",
    "        output = torch.softmax(logits, dim = -1)\n",
    "\n",
    "        output = torch.argmax(output, dim = -1)\n",
    "        # output : (bs, seq_len), dtype=int64\n",
    "\n",
    "\n",
    "\n",
    "        return logits, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, N = 2, hidden_dim = 256, num_head = 8, inner_dim = 512):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(N, hidden_dim, num_head, inner_dim)\n",
    "        self.decoder = Decoder(N, hidden_dim, num_head, inner_dim)\n",
    "\n",
    "    def forward(self, enc_src, dec_src):\n",
    "        # enc_src : (bs, seq_len)\n",
    "        # dec_src : (bs, seq_len)\n",
    "\n",
    "        # print(f'enc_src : {enc_src.shape}')\n",
    "        # print(f'dec_src : {dec_src.shape}')\n",
    "\n",
    "        enc_output = self.encoder(enc_src)\n",
    "        # enc_output : (bs, seq_len, hidden_dim)\n",
    "        logits, output = self.decoder(dec_src, enc_src, enc_output)\n",
    "        # logits = (bs, seq_len, VOCAB_SIZE) \n",
    "\n",
    "        return logits, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(N, HIDDEN_DIM, NUM_HEAD, INNER_DIM).to(device)\n",
    "ic.disable() #ic를 통해 debug를 쉽게해주는데 => 이를 비활성화 시킴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Encoder: 1-1                                [-1, 60, 256]             --\n",
      "|    └─Embedding: 2-1                         [-1, 60, 256]             1,280,000\n",
      "|    └─Embedding: 2-2                         [-1, 60, 256]             25,600\n",
      "|    └─Dropout: 2-3                           [-1, 60, 256]             --\n",
      "|    └─Dropout: 2-4                           [-1, 60, 256]             --\n",
      "|    └─ModuleList: 2                          []                        --\n",
      "|    |    └─EncoderLayer: 3-1                 [-1, 60, 256]             527,104\n",
      "|    |    └─EncoderLayer: 3-2                 [-1, 60, 256]             527,104\n",
      "├─Decoder: 1-2                                [-1, 60, 5000]            --\n",
      "|    └─Embedding: 2-5                         [-1, 60, 256]             1,280,000\n",
      "|    └─Dropout: 2-6                           [-1, 60, 256]             --\n",
      "|    └─ModuleList: 2                          []                        --\n",
      "|    |    └─DecoderLayer: 3-3                 [-1, 60, 256]             790,784\n",
      "|    |    └─DecoderLayer: 3-4                 [-1, 60, 256]             790,784\n",
      "|    └─Linear: 2-7                            [-1, 60, 5000]            1,285,000\n",
      "===============================================================================================\n",
      "Total params: 6,506,376\n",
      "Trainable params: 6,506,376\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 15.63\n",
      "===============================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.81\n",
      "Params size (MB): 24.82\n",
      "Estimated Total Size (MB): 28.63\n",
      "===============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "├─Encoder: 1-1                                [-1, 60, 256]             --\n",
       "|    └─Embedding: 2-1                         [-1, 60, 256]             1,280,000\n",
       "|    └─Embedding: 2-2                         [-1, 60, 256]             25,600\n",
       "|    └─Dropout: 2-3                           [-1, 60, 256]             --\n",
       "|    └─Dropout: 2-4                           [-1, 60, 256]             --\n",
       "|    └─ModuleList: 2                          []                        --\n",
       "|    |    └─EncoderLayer: 3-1                 [-1, 60, 256]             527,104\n",
       "|    |    └─EncoderLayer: 3-2                 [-1, 60, 256]             527,104\n",
       "├─Decoder: 1-2                                [-1, 60, 5000]            --\n",
       "|    └─Embedding: 2-5                         [-1, 60, 256]             1,280,000\n",
       "|    └─Dropout: 2-6                           [-1, 60, 256]             --\n",
       "|    └─ModuleList: 2                          []                        --\n",
       "|    |    └─DecoderLayer: 3-3                 [-1, 60, 256]             790,784\n",
       "|    |    └─DecoderLayer: 3-4                 [-1, 60, 256]             790,784\n",
       "|    └─Linear: 2-7                            [-1, 60, 5000]            1,285,000\n",
       "===============================================================================================\n",
       "Total params: 6,506,376\n",
       "Trainable params: 6,506,376\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 15.63\n",
       "===============================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 3.81\n",
       "Params size (MB): 24.82\n",
       "Estimated Total Size (MB): 28.63\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "test1 = torch.randint(low = 0, high = 1000, size = (SEQ_LEN,))\n",
    "test2 = torch.randint(low = 0, high = 1000, size = (SEQ_LEN,))\n",
    "summary(model, [(SEQ_LEN,), (SEQ_LEN,)], dtypes = [torch.int, torch.int])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.named_parameters():\n",
    "    if 'weight' in param[0] and 'layerNorm' not in param[0] :\n",
    "        torch.nn.init.xavier_uniform_(param[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(logits: torch.tensor, targets: torch.tensor):\n",
    "    return nn.CrossEntropyLoss(ignore_index=PAD_IDX)(logits.view(-1,VOCAB_SIZE), targets.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    # train 모드로 변경\n",
    "    model.train()\n",
    "\n",
    "    # for the Mixed Precision\n",
    "    # Pytorch 예제 : https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples\n",
    "    if(FP16):\n",
    "        scaler = amp.GradScaler()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "    running_accuracy = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "\n",
    "    for step, (src, trg_input, trg_output) in bar:\n",
    "        src = src.to(device)\n",
    "        trg_input = trg_input.to(device)\n",
    "        trg_output = trg_output.to(device)\n",
    "\n",
    "        batch_size = src.shape[0]\n",
    "\n",
    "        if(FP16):\n",
    "            with amp.autocast(enabled=True):\n",
    "                logits, output = model(enc_src=src, dec_src=trg_input)\n",
    "                loss = criterion(logits, trg_output)\n",
    "\n",
    "                # loss를 Scale\n",
    "                # Scaled Grdients를 계산(call)하기 위해 scaled loss를 backward()\n",
    "                scaler.scale(loss).backward()\n",
    "                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "                # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "                # otherwise, optimizer.step() is skipped.\n",
    "                scaler.step(optimizer)\n",
    "\n",
    "                # Updates the scale for next iteration.\n",
    "                scaler.update()\n",
    "\n",
    "        else:\n",
    "            logits, output = model(enc_src=src, dec_src=trg_input)\n",
    "            loss = criterion(logits, trg_output)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "\n",
    "        # logits (bs, seq_len, VOCAB_SIZE)\n",
    "        # trg_output (bs, seq_len)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # change learning rate by Scheduler\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # loss.item()은 loss를 Python Float으로 반환\n",
    "        # loss.item()은 batch data의 average loss이므로, sum of loss를 구하기 위해 batch_size를 곱해준다\n",
    "        running_loss += loss.item() * batch_size\n",
    "        running_accuracy = np.mean(\n",
    "            output.view(-1).detach().cpu().numpy() == trg_output.view(-1).detach().cpu().numpy())\n",
    "\n",
    "        accuracy += running_accuracy\n",
    "\n",
    "        dataset_size += batch_size\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        bar.set_postfix(\n",
    "            Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy=accuracy / float(\n",
    "                step+1)\n",
    "        )\n",
    "\n",
    "        # break\n",
    "\n",
    "    accuracy /= len(dataloader)\n",
    "    # Garbage Collector\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "\n",
    "    for step, (src, trg_input, trg_output) in bar:\n",
    "        src = src.to(device)\n",
    "        trg_input = trg_input.to(device)\n",
    "        trg_output = trg_output.to(device)\n",
    "\n",
    "        batch_size = src.shape[0]\n",
    "\n",
    "        logits, output = model(enc_src = src, dec_src = trg_input)\n",
    "        loss = criterion(logits, trg_output)\n",
    "\n",
    "        running_loss += loss.item() * batch_size\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        # 실시간으로 정보를 표시하기 위한 epoch loss\n",
    "        val_loss = running_loss / dataset_size\n",
    "        running_accuracy = np.mean(output.view(-1).detach().cpu().numpy() == trg_output.view(-1).detach().cpu().numpy())\n",
    "        \n",
    "        accuracy += running_accuracy\n",
    "\n",
    "        bar.set_postfix(\n",
    "            Epoch=epoch, Valid_Loss=val_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy = accuracy / float(step + 1)\n",
    "        )\n",
    "\n",
    "        # break\n",
    "\n",
    "    accuracy /= len(dataloader)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    file_prefix=\"\",\n",
    "    early_stopping=True,\n",
    "    early_stopping_step=10,\n",
    "):\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU:{}\\n\".format(torch.cuda.get_device_name()))\n",
    "\n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        gc.collect()\n",
    "\n",
    "        train_epoch_loss, train_accuracy = train_one_epoch(\n",
    "            model,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            dataloader=train_dataloader,\n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "\n",
    "        val_loss, val_accuracy = valid_one_epoch(\n",
    "            model, valid_dataloader, device=device, epoch=epoch\n",
    "        )\n",
    "\n",
    "        # Log metrics\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_epoch_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Valid Loss: {val_loss:.4f}, Valid Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Update history\n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Train Accuracy'].append(train_accuracy)\n",
    "        history['Valid Loss'].append(val_loss)\n",
    "        history['Valid Accuracy'].append(val_accuracy)\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss <= best_loss:\n",
    "            early_stop_counter = 0\n",
    "            print(f\"Validation Loss improved ({best_loss:.4f} ---> {val_loss:.4f})\")\n",
    "\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            # Save model weights\n",
    "            model_path = f\"{file_prefix}epoch_{epoch}_loss_{best_loss:.4f}.pth\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"Model Saved: {model_path}\")\n",
    "\n",
    "        elif early_stopping:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter > early_stopping_step:\n",
    "                break\n",
    "\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print(\n",
    "        \"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n",
    "            time_elapsed // 3600,\n",
    "            (time_elapsed % 3600) // 60,\n",
    "            (time_elapsed % 3600) % 60,\n",
    "        )\n",
    "    )\n",
    "    print(\"Best Loss: {:.4f}\".format(best_loss))\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/389 [00:00<?, ?it/s]c:\\Users\\thoma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "100%|██████████| 389/389 [06:00<00:00,  1.08it/s, Epoch=1, LR=9.73e-5, Train_Loss=7.4, accuracy=0.0281] \n",
      "100%|██████████| 98/98 [00:38<00:00,  2.57it/s, Epoch=1, LR=9.73e-5, Valid_Loss=7.06, accuracy=0.0577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 7.4007, Train Accuracy: 0.0281\n",
      "Epoch [1/50], Valid Loss: 7.0619, Valid Accuracy: 0.0577\n",
      "Validation Loss improved (inf ---> 7.0619)\n",
      "Model Saved: ./model/epoch_1_loss_7.0619.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:40<00:00,  1.14it/s, Epoch=2, LR=8.97e-5, Train_Loss=6.76, accuracy=0.0657]\n",
      "100%|██████████| 98/98 [00:41<00:00,  2.35it/s, Epoch=2, LR=8.97e-5, Valid_Loss=6.46, accuracy=0.0707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Train Loss: 6.7609, Train Accuracy: 0.0657\n",
      "Epoch [2/50], Valid Loss: 6.4610, Valid Accuracy: 0.0707\n",
      "Validation Loss improved (7.0619 ---> 6.4610)\n",
      "Model Saved: ./model/epoch_2_loss_6.4610.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:24<00:00,  1.20it/s, Epoch=3, LR=7.79e-5, Train_Loss=6.26, accuracy=0.0751]\n",
      "100%|██████████| 98/98 [00:35<00:00,  2.74it/s, Epoch=3, LR=7.79e-5, Valid_Loss=6.04, accuracy=0.0804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Train Loss: 6.2613, Train Accuracy: 0.0751\n",
      "Epoch [3/50], Valid Loss: 6.0436, Valid Accuracy: 0.0804\n",
      "Validation Loss improved (6.4610 ---> 6.0436)\n",
      "Model Saved: ./model/epoch_3_loss_6.0436.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:27<00:00,  1.19it/s, Epoch=4, LR=6.34e-5, Train_Loss=5.93, accuracy=0.0831]\n",
      "100%|██████████| 98/98 [00:36<00:00,  2.69it/s, Epoch=4, LR=6.34e-5, Valid_Loss=5.77, accuracy=0.0873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Train Loss: 5.9331, Train Accuracy: 0.0831\n",
      "Epoch [4/50], Valid Loss: 5.7706, Valid Accuracy: 0.0873\n",
      "Validation Loss improved (6.0436 ---> 5.7706)\n",
      "Model Saved: ./model/epoch_4_loss_5.7706.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:28<00:00,  1.19it/s, Epoch=5, LR=4.8e-5, Train_Loss=5.7, accuracy=0.0898]  \n",
      "100%|██████████| 98/98 [00:36<00:00,  2.70it/s, Epoch=5, LR=4.8e-5, Valid_Loss=5.56, accuracy=0.0939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Train Loss: 5.6966, Train Accuracy: 0.0898\n",
      "Epoch [5/50], Valid Loss: 5.5615, Valid Accuracy: 0.0939\n",
      "Validation Loss improved (5.7706 ---> 5.5615)\n",
      "Model Saved: ./model/epoch_5_loss_5.5615.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:18<00:00,  1.22it/s, Epoch=6, LR=3.33e-5, Train_Loss=5.51, accuracy=0.0954]\n",
      "100%|██████████| 98/98 [00:35<00:00,  2.79it/s, Epoch=6, LR=3.33e-5, Valid_Loss=5.4, accuracy=0.0984] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Train Loss: 5.5100, Train Accuracy: 0.0954\n",
      "Epoch [6/50], Valid Loss: 5.3964, Valid Accuracy: 0.0984\n",
      "Validation Loss improved (5.5615 ---> 5.3964)\n",
      "Model Saved: ./model/epoch_6_loss_5.3964.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:13<00:00,  1.24it/s, Epoch=7, LR=2.12e-5, Train_Loss=5.36, accuracy=0.0997]\n",
      "100%|██████████| 98/98 [00:35<00:00,  2.77it/s, Epoch=7, LR=2.12e-5, Valid_Loss=5.26, accuracy=0.102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Train Loss: 5.3568, Train Accuracy: 0.0997\n",
      "Epoch [7/50], Valid Loss: 5.2574, Valid Accuracy: 0.1021\n",
      "Validation Loss improved (5.3964 ---> 5.2574)\n",
      "Model Saved: ./model/epoch_7_loss_5.2574.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:26<00:00,  1.19it/s, Epoch=8, LR=1.32e-5, Train_Loss=5.22, accuracy=0.103]\n",
      "100%|██████████| 98/98 [00:35<00:00,  2.78it/s, Epoch=8, LR=1.32e-5, Valid_Loss=5.14, accuracy=0.105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Train Loss: 5.2201, Train Accuracy: 0.1034\n",
      "Epoch [8/50], Valid Loss: 5.1392, Valid Accuracy: 0.1051\n",
      "Validation Loss improved (5.2574 ---> 5.1392)\n",
      "Model Saved: ./model/epoch_8_loss_5.1392.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:14<00:00,  1.24it/s, Epoch=9, LR=1e-5, Train_Loss=5.1, accuracy=0.106]    \n",
      "100%|██████████| 98/98 [00:35<00:00,  2.73it/s, Epoch=9, LR=1e-5, Valid_Loss=5.04, accuracy=0.107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Train Loss: 5.0995, Train Accuracy: 0.1063\n",
      "Epoch [9/50], Valid Loss: 5.0354, Valid Accuracy: 0.1075\n",
      "Validation Loss improved (5.1392 ---> 5.0354)\n",
      "Model Saved: ./model/epoch_9_loss_5.0354.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:18<00:00,  1.22it/s, Epoch=10, LR=1.22e-5, Train_Loss=4.99, accuracy=0.109]\n",
      "100%|██████████| 98/98 [00:34<00:00,  2.80it/s, Epoch=10, LR=1.22e-5, Valid_Loss=4.95, accuracy=0.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Loss: 4.9941, Train Accuracy: 0.1089\n",
      "Epoch [10/50], Valid Loss: 4.9454, Valid Accuracy: 0.1095\n",
      "Validation Loss improved (5.0354 ---> 4.9454)\n",
      "Model Saved: ./model/epoch_10_loss_4.9454.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:13<00:00,  1.24it/s, Epoch=11, LR=1.94e-5, Train_Loss=4.9, accuracy=0.111] \n",
      "100%|██████████| 98/98 [00:35<00:00,  2.80it/s, Epoch=11, LR=1.94e-5, Valid_Loss=4.87, accuracy=0.112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Train Loss: 4.8989, Train Accuracy: 0.1112\n",
      "Epoch [11/50], Valid Loss: 4.8694, Valid Accuracy: 0.1115\n",
      "Validation Loss improved (4.9454 ---> 4.8694)\n",
      "Model Saved: ./model/epoch_11_loss_4.8694.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:06<00:00,  1.27it/s, Epoch=12, LR=3.09e-5, Train_Loss=4.81, accuracy=0.113]\n",
      "100%|██████████| 98/98 [00:34<00:00,  2.81it/s, Epoch=12, LR=3.09e-5, Valid_Loss=4.8, accuracy=0.113] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Train Loss: 4.8142, Train Accuracy: 0.1130\n",
      "Epoch [12/50], Valid Loss: 4.7993, Valid Accuracy: 0.1127\n",
      "Validation Loss improved (4.8694 ---> 4.7993)\n",
      "Model Saved: ./model/epoch_12_loss_4.7993.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:03<00:00,  1.28it/s, Epoch=13, LR=4.52e-5, Train_Loss=4.74, accuracy=0.115]\n",
      "100%|██████████| 98/98 [00:35<00:00,  2.78it/s, Epoch=13, LR=4.52e-5, Valid_Loss=4.74, accuracy=0.114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Train Loss: 4.7361, Train Accuracy: 0.1148\n",
      "Epoch [13/50], Valid Loss: 4.7387, Valid Accuracy: 0.1144\n",
      "Validation Loss improved (4.7993 ---> 4.7387)\n",
      "Model Saved: ./model/epoch_13_loss_4.7387.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:12<00:00,  1.24it/s, Epoch=14, LR=6.06e-5, Train_Loss=4.67, accuracy=0.117]\n",
      "100%|██████████| 98/98 [00:35<00:00,  2.74it/s, Epoch=14, LR=6.06e-5, Valid_Loss=4.68, accuracy=0.116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Train Loss: 4.6655, Train Accuracy: 0.1166\n",
      "Epoch [14/50], Valid Loss: 4.6850, Valid Accuracy: 0.1158\n",
      "Validation Loss improved (4.7387 ---> 4.6850)\n",
      "Model Saved: ./model/epoch_14_loss_4.6850.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:09<00:00,  1.26it/s, Epoch=15, LR=7.54e-5, Train_Loss=4.6, accuracy=0.118] \n",
      "100%|██████████| 98/98 [00:35<00:00,  2.79it/s, Epoch=15, LR=7.54e-5, Valid_Loss=4.64, accuracy=0.117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Train Loss: 4.6002, Train Accuracy: 0.1182\n",
      "Epoch [15/50], Valid Loss: 4.6387, Valid Accuracy: 0.1168\n",
      "Validation Loss improved (4.6850 ---> 4.6387)\n",
      "Model Saved: ./model/epoch_15_loss_4.6387.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:05<00:00,  1.27it/s, Epoch=16, LR=8.78e-5, Train_Loss=4.54, accuracy=0.12] \n",
      "100%|██████████| 98/98 [00:35<00:00,  2.77it/s, Epoch=16, LR=8.78e-5, Valid_Loss=4.59, accuracy=0.118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Train Loss: 4.5408, Train Accuracy: 0.1197\n",
      "Epoch [16/50], Valid Loss: 4.5915, Valid Accuracy: 0.1181\n",
      "Validation Loss improved (4.6387 ---> 4.5915)\n",
      "Model Saved: ./model/epoch_16_loss_4.5915.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:10<00:00,  1.25it/s, Epoch=17, LR=9.63e-5, Train_Loss=4.49, accuracy=0.121]\n",
      "100%|██████████| 98/98 [00:35<00:00,  2.79it/s, Epoch=17, LR=9.63e-5, Valid_Loss=4.56, accuracy=0.119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Train Loss: 4.4872, Train Accuracy: 0.1211\n",
      "Epoch [17/50], Valid Loss: 4.5559, Valid Accuracy: 0.1193\n",
      "Validation Loss improved (4.5915 ---> 4.5559)\n",
      "Model Saved: ./model/epoch_17_loss_4.5559.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:04<00:00,  1.28it/s, Epoch=18, LR=9.99e-5, Train_Loss=4.44, accuracy=0.122]\n",
      "100%|██████████| 98/98 [00:34<00:00,  2.82it/s, Epoch=18, LR=9.99e-5, Valid_Loss=4.52, accuracy=0.12] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Train Loss: 4.4381, Train Accuracy: 0.1222\n",
      "Epoch [18/50], Valid Loss: 4.5214, Valid Accuracy: 0.1204\n",
      "Validation Loss improved (4.5559 ---> 4.5214)\n",
      "Model Saved: ./model/epoch_18_loss_4.5214.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:03<00:00,  1.28it/s, Epoch=19, LR=9.82e-5, Train_Loss=4.39, accuracy=0.124]\n",
      "100%|██████████| 98/98 [00:34<00:00,  2.80it/s, Epoch=19, LR=9.82e-5, Valid_Loss=4.49, accuracy=0.122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Train Loss: 4.3915, Train Accuracy: 0.1236\n",
      "Epoch [19/50], Valid Loss: 4.4881, Valid Accuracy: 0.1215\n",
      "Validation Loss improved (4.5214 ---> 4.4881)\n",
      "Model Saved: ./model/epoch_19_loss_4.4881.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:14<00:00,  1.24it/s, Epoch=20, LR=9.14e-5, Train_Loss=4.35, accuracy=0.125]\n",
      "100%|██████████| 98/98 [00:34<00:00,  2.86it/s, Epoch=20, LR=9.14e-5, Valid_Loss=4.45, accuracy=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Train Loss: 4.3487, Train Accuracy: 0.1249\n",
      "Epoch [20/50], Valid Loss: 4.4498, Valid Accuracy: 0.1230\n",
      "Validation Loss improved (4.4881 ---> 4.4498)\n",
      "Model Saved: ./model/epoch_20_loss_4.4498.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:16<00:00,  1.23it/s, Epoch=21, LR=8.03e-5, Train_Loss=4.31, accuracy=0.126]\n",
      "100%|██████████| 98/98 [00:36<00:00,  2.70it/s, Epoch=21, LR=8.03e-5, Valid_Loss=4.42, accuracy=0.124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Train Loss: 4.3080, Train Accuracy: 0.1261\n",
      "Epoch [21/50], Valid Loss: 4.4169, Valid Accuracy: 0.1241\n",
      "Validation Loss improved (4.4498 ---> 4.4169)\n",
      "Model Saved: ./model/epoch_21_loss_4.4169.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:18<00:00,  1.22it/s, Epoch=22, LR=6.62e-5, Train_Loss=4.27, accuracy=0.128]\n",
      "100%|██████████| 98/98 [00:35<00:00,  2.75it/s, Epoch=22, LR=6.62e-5, Valid_Loss=4.39, accuracy=0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Train Loss: 4.2659, Train Accuracy: 0.1276\n",
      "Epoch [22/50], Valid Loss: 4.3853, Valid Accuracy: 0.1255\n",
      "Validation Loss improved (4.4169 ---> 4.3853)\n",
      "Model Saved: ./model/epoch_22_loss_4.3853.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:30<00:00,  1.18it/s, Epoch=23, LR=5.08e-5, Train_Loss=4.23, accuracy=0.129]\n",
      "100%|██████████| 98/98 [00:37<00:00,  2.64it/s, Epoch=23, LR=5.08e-5, Valid_Loss=4.36, accuracy=0.127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Train Loss: 4.2277, Train Accuracy: 0.1287\n",
      "Epoch [23/50], Valid Loss: 4.3575, Valid Accuracy: 0.1267\n",
      "Validation Loss improved (4.3853 ---> 4.3575)\n",
      "Model Saved: ./model/epoch_23_loss_4.3575.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:30<00:00,  1.18it/s, Epoch=24, LR=3.58e-5, Train_Loss=4.19, accuracy=0.13] \n",
      "100%|██████████| 98/98 [00:36<00:00,  2.66it/s, Epoch=24, LR=3.58e-5, Valid_Loss=4.33, accuracy=0.128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Train Loss: 4.1897, Train Accuracy: 0.1302\n",
      "Epoch [24/50], Valid Loss: 4.3314, Valid Accuracy: 0.1276\n",
      "Validation Loss improved (4.3575 ---> 4.3314)\n",
      "Model Saved: ./model/epoch_24_loss_4.3314.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:28<00:00,  1.18it/s, Epoch=25, LR=2.32e-5, Train_Loss=4.15, accuracy=0.132]\n",
      "100%|██████████| 98/98 [00:36<00:00,  2.70it/s, Epoch=25, LR=2.32e-5, Valid_Loss=4.3, accuracy=0.129] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Train Loss: 4.1532, Train Accuracy: 0.1316\n",
      "Epoch [25/50], Valid Loss: 4.3039, Valid Accuracy: 0.1285\n",
      "Validation Loss improved (4.3314 ---> 4.3039)\n",
      "Model Saved: ./model/epoch_25_loss_4.3039.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:34<00:00,  1.16it/s, Epoch=26, LR=1.43e-5, Train_Loss=4.11, accuracy=0.133]\n",
      "100%|██████████| 98/98 [00:36<00:00,  2.67it/s, Epoch=26, LR=1.43e-5, Valid_Loss=4.28, accuracy=0.13] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Train Loss: 4.1142, Train Accuracy: 0.1331\n",
      "Epoch [26/50], Valid Loss: 4.2785, Valid Accuracy: 0.1299\n",
      "Validation Loss improved (4.3039 ---> 4.2785)\n",
      "Model Saved: ./model/epoch_26_loss_4.2785.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:35<00:00,  1.16it/s, Epoch=27, LR=1.02e-5, Train_Loss=4.08, accuracy=0.134]\n",
      "100%|██████████| 98/98 [00:37<00:00,  2.59it/s, Epoch=27, LR=1.02e-5, Valid_Loss=4.25, accuracy=0.131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Train Loss: 4.0792, Train Accuracy: 0.1343\n",
      "Epoch [27/50], Valid Loss: 4.2548, Valid Accuracy: 0.1306\n",
      "Validation Loss improved (4.2785 ---> 4.2548)\n",
      "Model Saved: ./model/epoch_27_loss_4.2548.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:35<00:00,  1.16it/s, Epoch=28, LR=1.14e-5, Train_Loss=4.04, accuracy=0.136]\n",
      "100%|██████████| 98/98 [00:36<00:00,  2.72it/s, Epoch=28, LR=1.14e-5, Valid_Loss=4.23, accuracy=0.132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Train Loss: 4.0439, Train Accuracy: 0.1357\n",
      "Epoch [28/50], Valid Loss: 4.2311, Valid Accuracy: 0.1320\n",
      "Validation Loss improved (4.2548 ---> 4.2311)\n",
      "Model Saved: ./model/epoch_28_loss_4.2311.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:37<00:00,  1.15it/s, Epoch=29, LR=1.78e-5, Train_Loss=4.01, accuracy=0.137]\n",
      "100%|██████████| 98/98 [00:37<00:00,  2.63it/s, Epoch=29, LR=1.78e-5, Valid_Loss=4.21, accuracy=0.133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Train Loss: 4.0077, Train Accuracy: 0.1373\n",
      "Epoch [29/50], Valid Loss: 4.2079, Valid Accuracy: 0.1331\n",
      "Validation Loss improved (4.2311 ---> 4.2079)\n",
      "Model Saved: ./model/epoch_29_loss_4.2079.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:32<00:00,  1.17it/s, Epoch=30, LR=2.85e-5, Train_Loss=3.97, accuracy=0.138]\n",
      "100%|██████████| 98/98 [00:38<00:00,  2.53it/s, Epoch=30, LR=2.85e-5, Valid_Loss=4.19, accuracy=0.134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Train Loss: 3.9750, Train Accuracy: 0.1384\n",
      "Epoch [30/50], Valid Loss: 4.1879, Valid Accuracy: 0.1339\n",
      "Validation Loss improved (4.2079 ---> 4.1879)\n",
      "Model Saved: ./model/epoch_30_loss_4.1879.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:30<00:00,  1.18it/s, Epoch=31, LR=4.24e-5, Train_Loss=3.94, accuracy=0.14] \n",
      "100%|██████████| 98/98 [00:37<00:00,  2.59it/s, Epoch=31, LR=4.24e-5, Valid_Loss=4.17, accuracy=0.135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Train Loss: 3.9410, Train Accuracy: 0.1398\n",
      "Epoch [31/50], Valid Loss: 4.1676, Valid Accuracy: 0.1352\n",
      "Validation Loss improved (4.1879 ---> 4.1676)\n",
      "Model Saved: ./model/epoch_31_loss_4.1676.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:32<00:00,  1.17it/s, Epoch=32, LR=5.78e-5, Train_Loss=3.91, accuracy=0.141]\n",
      "100%|██████████| 98/98 [00:37<00:00,  2.61it/s, Epoch=32, LR=5.78e-5, Valid_Loss=4.15, accuracy=0.136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Train Loss: 3.9062, Train Accuracy: 0.1413\n",
      "Epoch [32/50], Valid Loss: 4.1497, Valid Accuracy: 0.1356\n",
      "Validation Loss improved (4.1676 ---> 4.1497)\n",
      "Model Saved: ./model/epoch_32_loss_4.1497.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:34<00:00,  1.16it/s, Epoch=33, LR=7.29e-5, Train_Loss=3.87, accuracy=0.143]\n",
      "100%|██████████| 98/98 [00:37<00:00,  2.60it/s, Epoch=33, LR=7.29e-5, Valid_Loss=4.13, accuracy=0.137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Train Loss: 3.8745, Train Accuracy: 0.1429\n",
      "Epoch [33/50], Valid Loss: 4.1269, Valid Accuracy: 0.1370\n",
      "Validation Loss improved (4.1497 ---> 4.1269)\n",
      "Model Saved: ./model/epoch_33_loss_4.1269.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:35<00:00,  1.16it/s, Epoch=34, LR=8.58e-5, Train_Loss=3.84, accuracy=0.144]\n",
      "100%|██████████| 98/98 [00:38<00:00,  2.53it/s, Epoch=34, LR=8.58e-5, Valid_Loss=4.11, accuracy=0.138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Train Loss: 3.8441, Train Accuracy: 0.1444\n",
      "Epoch [34/50], Valid Loss: 4.1114, Valid Accuracy: 0.1379\n",
      "Validation Loss improved (4.1269 ---> 4.1114)\n",
      "Model Saved: ./model/epoch_34_loss_4.1114.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:38<00:00,  1.15it/s, Epoch=35, LR=9.51e-5, Train_Loss=3.81, accuracy=0.146]\n",
      "100%|██████████| 98/98 [00:39<00:00,  2.51it/s, Epoch=35, LR=9.51e-5, Valid_Loss=4.09, accuracy=0.139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Train Loss: 3.8138, Train Accuracy: 0.1456\n",
      "Epoch [35/50], Valid Loss: 4.0911, Valid Accuracy: 0.1387\n",
      "Validation Loss improved (4.1114 ---> 4.0911)\n",
      "Model Saved: ./model/epoch_35_loss_4.0911.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:37<00:00,  1.15it/s, Epoch=36, LR=9.96e-5, Train_Loss=3.78, accuracy=0.147]\n",
      "100%|██████████| 98/98 [00:37<00:00,  2.60it/s, Epoch=36, LR=9.96e-5, Valid_Loss=4.07, accuracy=0.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Train Loss: 3.7846, Train Accuracy: 0.1471\n",
      "Epoch [36/50], Valid Loss: 4.0740, Valid Accuracy: 0.1401\n",
      "Validation Loss improved (4.0911 ---> 4.0740)\n",
      "Model Saved: ./model/epoch_36_loss_4.0740.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:36<00:00,  1.16it/s, Epoch=37, LR=9.89e-5, Train_Loss=3.76, accuracy=0.148]\n",
      "100%|██████████| 98/98 [00:37<00:00,  2.62it/s, Epoch=37, LR=9.89e-5, Valid_Loss=4.06, accuracy=0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Train Loss: 3.7569, Train Accuracy: 0.1484\n",
      "Epoch [37/50], Valid Loss: 4.0563, Valid Accuracy: 0.1407\n",
      "Validation Loss improved (4.0740 ---> 4.0563)\n",
      "Model Saved: ./model/epoch_37_loss_4.0563.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:37<00:00,  1.15it/s, Epoch=38, LR=9.3e-5, Train_Loss=3.73, accuracy=0.15]  \n",
      "100%|██████████| 98/98 [00:38<00:00,  2.52it/s, Epoch=38, LR=9.3e-5, Valid_Loss=4.04, accuracy=0.142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Train Loss: 3.7285, Train Accuracy: 0.1496\n",
      "Epoch [38/50], Valid Loss: 4.0382, Valid Accuracy: 0.1418\n",
      "Validation Loss improved (4.0563 ---> 4.0382)\n",
      "Model Saved: ./model/epoch_38_loss_4.0382.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:35<00:00,  1.16it/s, Epoch=39, LR=8.26e-5, Train_Loss=3.7, accuracy=0.151] \n",
      "100%|██████████| 98/98 [00:38<00:00,  2.52it/s, Epoch=39, LR=8.26e-5, Valid_Loss=4.02, accuracy=0.143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Train Loss: 3.7007, Train Accuracy: 0.1509\n",
      "Epoch [39/50], Valid Loss: 4.0216, Valid Accuracy: 0.1425\n",
      "Validation Loss improved (4.0382 ---> 4.0216)\n",
      "Model Saved: ./model/epoch_39_loss_4.0216.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:39<00:00,  1.15it/s, Epoch=40, LR=6.89e-5, Train_Loss=3.67, accuracy=0.152]\n",
      "100%|██████████| 98/98 [00:37<00:00,  2.62it/s, Epoch=40, LR=6.89e-5, Valid_Loss=4, accuracy=0.144]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Train Loss: 3.6747, Train Accuracy: 0.1522\n",
      "Epoch [40/50], Valid Loss: 4.0043, Valid Accuracy: 0.1437\n",
      "Validation Loss improved (4.0216 ---> 4.0043)\n",
      "Model Saved: ./model/epoch_40_loss_4.0043.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:39<00:00,  1.14it/s, Epoch=41, LR=5.36e-5, Train_Loss=3.65, accuracy=0.154]\n",
      "100%|██████████| 98/98 [00:38<00:00,  2.56it/s, Epoch=41, LR=5.36e-5, Valid_Loss=3.99, accuracy=0.145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Train Loss: 3.6493, Train Accuracy: 0.1539\n",
      "Epoch [41/50], Valid Loss: 3.9903, Valid Accuracy: 0.1445\n",
      "Validation Loss improved (4.0043 ---> 3.9903)\n",
      "Model Saved: ./model/epoch_41_loss_3.9903.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:40<00:00,  1.14it/s, Epoch=42, LR=3.84e-5, Train_Loss=3.62, accuracy=0.155]\n",
      "100%|██████████| 98/98 [00:37<00:00,  2.60it/s, Epoch=42, LR=3.84e-5, Valid_Loss=3.97, accuracy=0.146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Train Loss: 3.6223, Train Accuracy: 0.1549\n",
      "Epoch [42/50], Valid Loss: 3.9720, Valid Accuracy: 0.1457\n",
      "Validation Loss improved (3.9903 ---> 3.9720)\n",
      "Model Saved: ./model/epoch_42_loss_3.9720.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:42<00:00,  1.14it/s, Epoch=43, LR=2.52e-5, Train_Loss=3.6, accuracy=0.156] \n",
      "100%|██████████| 98/98 [00:38<00:00,  2.53it/s, Epoch=43, LR=2.52e-5, Valid_Loss=3.96, accuracy=0.146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Train Loss: 3.5956, Train Accuracy: 0.1564\n",
      "Epoch [43/50], Valid Loss: 3.9593, Valid Accuracy: 0.1462\n",
      "Validation Loss improved (3.9720 ---> 3.9593)\n",
      "Model Saved: ./model/epoch_43_loss_3.9593.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:45<00:00,  1.13it/s, Epoch=44, LR=1.56e-5, Train_Loss=3.57, accuracy=0.158]\n",
      "100%|██████████| 98/98 [00:38<00:00,  2.57it/s, Epoch=44, LR=1.56e-5, Valid_Loss=3.94, accuracy=0.147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Train Loss: 3.5699, Train Accuracy: 0.1579\n",
      "Epoch [44/50], Valid Loss: 3.9440, Valid Accuracy: 0.1473\n",
      "Validation Loss improved (3.9593 ---> 3.9440)\n",
      "Model Saved: ./model/epoch_44_loss_3.9440.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:41<00:00,  1.14it/s, Epoch=45, LR=1.06e-5, Train_Loss=3.54, accuracy=0.159]\n",
      "100%|██████████| 98/98 [00:38<00:00,  2.52it/s, Epoch=45, LR=1.06e-5, Valid_Loss=3.93, accuracy=0.148]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Train Loss: 3.5438, Train Accuracy: 0.1594\n",
      "Epoch [45/50], Valid Loss: 3.9328, Valid Accuracy: 0.1480\n",
      "Validation Loss improved (3.9440 ---> 3.9328)\n",
      "Model Saved: ./model/epoch_45_loss_3.9328.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:46<00:00,  1.12it/s, Epoch=46, LR=1.08e-5, Train_Loss=3.52, accuracy=0.161]\n",
      "100%|██████████| 98/98 [00:38<00:00,  2.56it/s, Epoch=46, LR=1.08e-5, Valid_Loss=3.92, accuracy=0.149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Train Loss: 3.5191, Train Accuracy: 0.1606\n",
      "Epoch [46/50], Valid Loss: 3.9219, Valid Accuracy: 0.1490\n",
      "Validation Loss improved (3.9328 ---> 3.9219)\n",
      "Model Saved: ./model/epoch_46_loss_3.9219.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:49<00:00,  1.11it/s, Epoch=47, LR=1.63e-5, Train_Loss=3.49, accuracy=0.162]\n",
      "100%|██████████| 98/98 [00:38<00:00,  2.56it/s, Epoch=47, LR=1.63e-5, Valid_Loss=3.91, accuracy=0.15] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Train Loss: 3.4916, Train Accuracy: 0.1624\n",
      "Epoch [47/50], Valid Loss: 3.9124, Valid Accuracy: 0.1498\n",
      "Validation Loss improved (3.9219 ---> 3.9124)\n",
      "Model Saved: ./model/epoch_47_loss_3.9124.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:47<00:00,  1.12it/s, Epoch=48, LR=2.63e-5, Train_Loss=3.47, accuracy=0.164]\n",
      "100%|██████████| 98/98 [00:39<00:00,  2.51it/s, Epoch=48, LR=2.63e-5, Valid_Loss=3.9, accuracy=0.15]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Train Loss: 3.4675, Train Accuracy: 0.1637\n",
      "Epoch [48/50], Valid Loss: 3.9047, Valid Accuracy: 0.1499\n",
      "Validation Loss improved (3.9124 ---> 3.9047)\n",
      "Model Saved: ./model/epoch_48_loss_3.9047.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:47<00:00,  1.12it/s, Epoch=49, LR=3.98e-5, Train_Loss=3.44, accuracy=0.165]\n",
      "100%|██████████| 98/98 [00:39<00:00,  2.47it/s, Epoch=49, LR=3.98e-5, Valid_Loss=3.9, accuracy=0.151] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Train Loss: 3.4426, Train Accuracy: 0.1653\n",
      "Epoch [49/50], Valid Loss: 3.8974, Valid Accuracy: 0.1509\n",
      "Validation Loss improved (3.9047 ---> 3.8974)\n",
      "Model Saved: ./model/epoch_49_loss_3.8974.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [05:43<00:00,  1.13it/s, Epoch=50, LR=5.5e-5, Train_Loss=3.42, accuracy=0.167] \n",
      "100%|██████████| 98/98 [00:39<00:00,  2.50it/s, Epoch=50, LR=5.5e-5, Valid_Loss=3.89, accuracy=0.151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Train Loss: 3.4168, Train Accuracy: 0.1667\n",
      "Epoch [50/50], Valid Loss: 3.8889, Valid Accuracy: 0.1513\n",
      "Validation Loss improved (3.8974 ---> 3.8889)\n",
      "Model Saved: ./model/epoch_50_loss_3.8889.pth\n",
      "Training complete in 5h 5m 34s\n",
      "Best Loss: 3.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Transformer(\n",
       "   (encoder): Encoder(\n",
       "     (embedding): Embedding(5000, 256, padding_idx=0)\n",
       "     (pos_embedding): Embedding(100, 256)\n",
       "     (enc_layers): ModuleList(\n",
       "       (0-1): 2 x EncoderLayer(\n",
       "         (multiheadattention): Multiheadattention(\n",
       "           (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (ffn): FFN(\n",
       "           (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "           (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "           (relu): ReLU()\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (dropout1): Dropout(p=0.1, inplace=False)\n",
       "         (dropout2): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (decoder): Decoder(\n",
       "     (embedding): Embedding(5000, 256, padding_idx=0)\n",
       "     (pos_embedding): Embedding(100, 256)\n",
       "     (dec_layers): ModuleList(\n",
       "       (0-1): 2 x DecoderLayer(\n",
       "         (multiheadattention1): Multiheadattention(\n",
       "           (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (multiheadattention2): Multiheadattention(\n",
       "           (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (ffn): FFN(\n",
       "           (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "           (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "           (relu): ReLU()\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (layerNorm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (dropout1): Dropout(p=0.1, inplace=False)\n",
       "         (dropout2): Dropout(p=0.1, inplace=False)\n",
       "         (dropout3): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "     (finalFc): Linear(in_features=256, out_features=5000, bias=True)\n",
       "   )\n",
       " ),\n",
       " defaultdict(list,\n",
       "             {'Train Loss': [7.400698688115232,\n",
       "               6.760879393631501,\n",
       "               6.261348045260817,\n",
       "               5.933117640965603,\n",
       "               5.696611646545597,\n",
       "               5.509994267526271,\n",
       "               5.356759866085082,\n",
       "               5.220120680416981,\n",
       "               5.0994701442604295,\n",
       "               4.994066833017321,\n",
       "               4.898941537706587,\n",
       "               4.814152254052414,\n",
       "               4.736100021974453,\n",
       "               4.6654685636197755,\n",
       "               4.600248734216974,\n",
       "               4.540804229690797,\n",
       "               4.487238074021627,\n",
       "               4.438107814473776,\n",
       "               4.391514513877093,\n",
       "               4.348726321947334,\n",
       "               4.307971571638036,\n",
       "               4.265945168796308,\n",
       "               4.227650734742336,\n",
       "               4.1897258430088185,\n",
       "               4.153198200392627,\n",
       "               4.114181997863895,\n",
       "               4.079155640342834,\n",
       "               4.043918782777545,\n",
       "               4.007740883698242,\n",
       "               3.9749723556594287,\n",
       "               3.9410011225544275,\n",
       "               3.906185189239351,\n",
       "               3.8745057090840835,\n",
       "               3.844094748187141,\n",
       "               3.81377420610148,\n",
       "               3.7846295356041453,\n",
       "               3.7569179276209317,\n",
       "               3.728467666426833,\n",
       "               3.700700917715563,\n",
       "               3.6746543451208864,\n",
       "               3.649268463177921,\n",
       "               3.6222901721622134,\n",
       "               3.5956002136990555,\n",
       "               3.569915266400704,\n",
       "               3.54382024828713,\n",
       "               3.5190756959661824,\n",
       "               3.49163225684687,\n",
       "               3.467497525948907,\n",
       "               3.4425790920540416,\n",
       "               3.416838830782996],\n",
       "              'Train Accuracy': [0.028123411693297722,\n",
       "               0.06567804419325574,\n",
       "               0.07512496429591549,\n",
       "               0.08312718162457784,\n",
       "               0.08981979413444903,\n",
       "               0.09535384848026615,\n",
       "               0.0996622813649882,\n",
       "               0.10344035107616305,\n",
       "               0.10628506088596543,\n",
       "               0.10885841965320837,\n",
       "               0.11123818877379582,\n",
       "               0.11303329038342001,\n",
       "               0.11480753398188753,\n",
       "               0.11661715350236068,\n",
       "               0.1181983325142396,\n",
       "               0.11966042790295219,\n",
       "               0.12106538362988728,\n",
       "               0.12223418046524522,\n",
       "               0.12363162783322415,\n",
       "               0.12486824930272016,\n",
       "               0.12609037911437068,\n",
       "               0.1276069101055161,\n",
       "               0.12874718305274116,\n",
       "               0.13023970567232898,\n",
       "               0.131566401196297,\n",
       "               0.13312107780130042,\n",
       "               0.13430683407681834,\n",
       "               0.13565592341263832,\n",
       "               0.1372683960045029,\n",
       "               0.1384489410588571,\n",
       "               0.1397587427751734,\n",
       "               0.14132459003309972,\n",
       "               0.1428803955172471,\n",
       "               0.14439129523917524,\n",
       "               0.14563923175311255,\n",
       "               0.14709192856662803,\n",
       "               0.14844254057664197,\n",
       "               0.1495568099240553,\n",
       "               0.1509499649259875,\n",
       "               0.1522041890342255,\n",
       "               0.15387730606381372,\n",
       "               0.1549025383503873,\n",
       "               0.1564079643211184,\n",
       "               0.15793049412352766,\n",
       "               0.1594383616235699,\n",
       "               0.16060433626106824,\n",
       "               0.1623789080220777,\n",
       "               0.16374886849555584,\n",
       "               0.1652922694356234,\n",
       "               0.16670348650385594],\n",
       "              'Valid Loss': [7.061922884853567,\n",
       "               6.460964531324393,\n",
       "               6.043562571079933,\n",
       "               5.77056732823124,\n",
       "               5.561451319424866,\n",
       "               5.396360454136221,\n",
       "               5.2574371451485336,\n",
       "               5.139166303854474,\n",
       "               5.035365031781524,\n",
       "               4.945431291089336,\n",
       "               4.869446784042312,\n",
       "               4.799269818853401,\n",
       "               4.738700585701787,\n",
       "               4.68495178452605,\n",
       "               4.638652037777063,\n",
       "               4.591452815643443,\n",
       "               4.55593884594857,\n",
       "               4.521425092360192,\n",
       "               4.488100431831947,\n",
       "               4.449766444117477,\n",
       "               4.4168512067348695,\n",
       "               4.385251068451879,\n",
       "               4.357530340391845,\n",
       "               4.331407297502624,\n",
       "               4.30387358043838,\n",
       "               4.2784628709438355,\n",
       "               4.25482198199818,\n",
       "               4.231119904903675,\n",
       "               4.207945420952438,\n",
       "               4.187910142732076,\n",
       "               4.167597958789035,\n",
       "               4.149717853606236,\n",
       "               4.126853589899688,\n",
       "               4.111390378424984,\n",
       "               4.091133438224406,\n",
       "               4.073987557485237,\n",
       "               4.056259635483178,\n",
       "               4.038208907525498,\n",
       "               4.021624099593169,\n",
       "               4.004290584160419,\n",
       "               3.990257290509176,\n",
       "               3.971968545233048,\n",
       "               3.959258823221547,\n",
       "               3.9440086796589937,\n",
       "               3.9328417876126625,\n",
       "               3.9219252154520903,\n",
       "               3.912407487558985,\n",
       "               3.9047426502912725,\n",
       "               3.89735005331507,\n",
       "               3.8888674721306224],\n",
       "              'Valid Accuracy': [0.05767799908424909,\n",
       "               0.07069106488749345,\n",
       "               0.08041785223704866,\n",
       "               0.08733034079016228,\n",
       "               0.09394929846938775,\n",
       "               0.09841808117477759,\n",
       "               0.10207188644688645,\n",
       "               0.10511859791993723,\n",
       "               0.10747890502354793,\n",
       "               0.10951440672422816,\n",
       "               0.11152844551282048,\n",
       "               0.11268192373103089,\n",
       "               0.11442266810570387,\n",
       "               0.1157515289769754,\n",
       "               0.1168085262951334,\n",
       "               0.11811060962846673,\n",
       "               0.1192591820381999,\n",
       "               0.12039262820512828,\n",
       "               0.12151892006802725,\n",
       "               0.12297533195970695,\n",
       "               0.1241457760989011,\n",
       "               0.12545378728414439,\n",
       "               0.12665734563055994,\n",
       "               0.127621336996337,\n",
       "               0.1285460818942962,\n",
       "               0.12991970826792257,\n",
       "               0.13062123888016747,\n",
       "               0.1319580716902146,\n",
       "               0.13311073227367862,\n",
       "               0.1338899381868132,\n",
       "               0.13524966476975409,\n",
       "               0.13561616954474093,\n",
       "               0.13696322278911563,\n",
       "               0.137888785321821,\n",
       "               0.13868781887755105,\n",
       "               0.14009885204081637,\n",
       "               0.1407051282051282,\n",
       "               0.14181547619047624,\n",
       "               0.142538469714809,\n",
       "               0.1436911302982732,\n",
       "               0.1445208251569859,\n",
       "               0.14569494865253788,\n",
       "               0.1462441947933019,\n",
       "               0.14731570512820513,\n",
       "               0.14795448227367877,\n",
       "               0.14896283032443747,\n",
       "               0.1497573668890633,\n",
       "               0.14988573554421766,\n",
       "               0.1509445725405547,\n",
       "               0.15126447213500785]}))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_training(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=100, eta_min=1e-5),\n",
    "    device=device,\n",
    "    num_epochs=50,\n",
    "    train_dataloader= train_dataloader,\n",
    "    valid_dataloader = valid_dataloader,\n",
    "    file_prefix=\"./model/\",\n",
    "    early_stopping=True,\n",
    "    early_stopping_step=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'final.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(src_sentence):\n",
    "    # Prepare Sample Sentence\n",
    "    dec_sentence = ''\n",
    "\n",
    "    enc_src = sp_src.EncodeAsIds(src_sentence)\n",
    "    dec_src = []\n",
    "    dec_src = np.insert(dec_src, 0, sp_trg.bos_id())\n",
    "    # dec_src = ko_encode(dec_sentence)\n",
    "\n",
    "    enc_src = torch.Tensor(enc_src).view(1, -1).int().to(device)\n",
    "    dec_src = torch.Tensor(dec_src).view(1, -1).int().to(device)\n",
    "    # enc_src : (1,seq_len)\n",
    "    # dec_src : (1,seq_len)\n",
    "\n",
    "    last_token = None\n",
    "    last_token_idx = 0\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        # dec_src에 dec_output의 last token을 추가합니다\n",
    "        enc_output = model.encoder(enc_src)\n",
    "        # enc_output : (1,seq_len, hidden_dim)\n",
    "\n",
    "        dec_logits, dec_output = model.decoder(\n",
    "            input=dec_src, enc_src=enc_src, enc_output=enc_output\n",
    "        )\n",
    "        # dec_output : (1,seq_len)\n",
    "        # dec_logits : (1, seq_len, VOCAB_SIZE)\n",
    "\n",
    "        last_token = dec_output[:, last_token_idx].item()\n",
    "        last_token = torch.Tensor([last_token]).view(-1, 1).int()\n",
    "\n",
    "        # last_token : (1, 1)\n",
    "        dec_src = torch.cat((dec_src, last_token), dim=-1)\n",
    "\n",
    "        last_token_idx = last_token_idx + 1\n",
    "\n",
    "        # print(dec_src)\n",
    "        # print(sp_trg.Decode(dec_src.tolist()))\n",
    "        # print(last_token.item())\n",
    "        if last_token.item() is EOS_IDX:\n",
    "            break\n",
    "\n",
    "    # ic(dec_src.tolist())\n",
    "    return sp_trg.Decode(dec_src.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en =  I would state my case before him and fill my mouth with arguments.\n",
      "answer =  그분 앞에서 내 사정을 아뢰련만, 내가 정당함을 입이 닳도록 변론하련만.\n",
      "ko = ['내가 내 말을 내 앞에 무릎을 꿇고, 내 입술로 내 입술로 내 입술로 내 입술로 내 입술로 나아오.']\n",
      "en =  Joseph threw himself upon his father and wept over him and kissed him.\n",
      "answer =  요셉이 아버지의 얼굴에 엎드려서, 울며 입을 맞추고,\n",
      "ko = ['요셉이 자기 아버지에게로 달려가서, 그에게 입을 맞추었다.']\n",
      "en =  It still remains that some will enter that rest, and those who formerly had the gospel preached to them did not go in, because of their disobedience.\n",
      "answer =  그러나 어떤 사람들에게는 안식에 들어갈 기회가 아직 남아 있습니다. 그런데 기쁜 소식을 먼저 들은 사람들은 순종하지 않았으므로, 들어갈 수 없었습니다.\n",
      "ko = ['그러나 그 때에 그들은 여러 가지로 내려가지 못할 것이다. 그들은 복음을 전체가 아니라, 복음을 전투하는 사람들을 시켜서, 이방 사람들에게로 내려왔습니다.']\n",
      "en =  But if your heart turns away and you are not obedient, and if you are drawn away to bow down to other gods and worship them,\n",
      "answer =  그러나 너희가 마음을 돌려서 순종하지 않고, 빗나가서 다른 신들에게 절을 하고 섬기면,\n",
      "ko = ['그러나 너희는, 너희의 마음을 다하여 주 너희의 하나님을 섬기며, 너희의 신상을 만들어 버리고, 너희의 신상을 만들어 버리고,']\n",
      "en =  Only be careful, and watch yourselves closely so that you do not forget the things your eyes have seen or let them slip from your heart as long as you live. Teach them to your children and to their children after them.\n",
      "answer =  너희는 오로지 삼가 조심하여, 너희의 눈으로 본 것들을 잊지 않도록, 정성을 기울여 지키고, 평생 동안 너희의 마음 속에서 사라지지 않도록 하여라. 또한 그것을 너희의 자손에게 길이 알려라.\n",
      "ko = ['너희는 너희가 알지 못하는 신들의 손에서 벗어나지 않고, 너희가 알지 못하는 너희의 조상을 따라, 너희가 하는 말을 듣지 않고, 너희가 하는 말을 듣지 않았다.']\n",
      "en =  \" 'But if you do not drive out the inhabitants of the land, those you allow to remain will become barbs in your eyes and thorns in your sides. They will give you trouble in the land where you will live.\n",
      "answer =  너희가 그 땅의 주민을 다 쫓아내지 아니하고, 너희와 함께 있도록 허락하였다가는, 그들이 너희 눈에 가시가 되고, 옆구리를 찌르는 바늘이 되어서, 너희가 살아갈 그 땅에서 너희를 괴롭힐 것이다.\n",
      "ko = ['그러나 너희가 사는 땅에서 사는 땅에서, 너희가 사는 땅에서 살든지, 너희가 사는 땅에서 살 것이다. 너희가 사는 땅에서 살 것이다. 너희가 사는 땅에서 살 것이다. 너희가 사는 땅에서 살 것이다.']\n",
      "en =  The sons of Shemida were: Ahian, Shechem, Likhi and Aniam.\n",
      "answer =  (스미다의 아들은 아히안과 세겜과 릭히와 아니암이다.)\n",
      "ko = ['야벳의 아들은 야완과 야완과 하맛과 하맛과 하맛과 하맛과 하맛과 하맛과 하맛과']\n",
      "en =  Remeth, En Gannim, En Haddah and Beth Pazzez.\n",
      "answer =  레멧과 언간님과 엔핫다와 벳바세스이다.\n",
      "ko = ['에셀과 에셀과 벳호론과 벳호론과 벳호론과']\n",
      "en =  and then twisted together a crown of thorns and set it on his head. They put a staff in his right hand and knelt in front of him and mocked him. \"Hail, king of the Jews!\" they said.\n",
      "answer =  가시로 면류관을 엮어 머리에 씌우고, 오른손에 갈대를 들게 하였다. 그리고 그의 앞에 무릎을 꿇고 \"유대인의 왕 만세!\" 하면서 희롱하였다.\n",
      "ko = ['그 때에 그는  ⁇ 을  ⁇ 을  ⁇ 고,  ⁇ 장으로  ⁇ 고, 자기 앞에 서서 \"그라!\" 하고 외쳤다. \"임금님께서 유다 왕좌우신 다음에, 왕의 손에 들고 계신다!\"']\n",
      "en =  Better a poor but wise youth than an old but foolish king who no longer knows how to take warning.\n",
      "answer =  아무리 나이가 많아도 신하의 직언을 듣지 않는, 왕은 어리석다. 그보다는 가난할지라도 슬기로운 젊은이가 더 낫다.\n",
      "ko = ['어리석은 사람은 어리석은 사람은, 지혜의 지혜의 지혜롭다고 해서, 지혜의 지혜롭다고 해서, 누가 감히 말인가?']\n"
     ]
    }
   ],
   "source": [
    "# Prepare 10 Sample Sentence\n",
    "indices = np.random.choice(len(data['en']), 10, replace=False)\n",
    "sentences = data['en'][indices].to_list()\n",
    "answers = data['ko'][indices].to_list()\n",
    "\n",
    "for idx in range(len(sentences)):\n",
    "    sentence = sentences[idx]\n",
    "    print(f'en = {sentence}')\n",
    "    print(f'answer = {answers[idx]}')\n",
    "    print(f'ko = {predict(sentence)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
